#!/usr/bin/env python3
# -*- coding: utf-8 -*-
'''
Points to remember from ML course

Supervised Learning:
    Linear Regression:
        loss function = (1 / 2m) * (y_true - y_pred)**2 
                        + (lambda / 2m) * (thetas ** 2)
                        
                        no regularisation of bias unit
        
        grad function += (alpha / m) * (y_true - y_pred).T * theta  
                        - (lambda / m) * theta
    
    Logisitic Regression:
        
        
    Neural Networks:
        
        
Unsupervised Learning:
    Clustering:
        
    Dimensionality Reduction (principal component analysis):
    
    
'''